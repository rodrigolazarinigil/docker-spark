# Creating and customizing your pysparkÂ image
> This repository contains the base code and some samples to build your custom spark docker image

## Building and testing the image

Most of the calls are represented inside the `Makefile`
The process does:
1. Download the base spark code
2. Builds the spark dockerfile for pyspark, without changing anything
3. Adds anothers dockerfile with GCS jar and another python requirements, as an example. 
You can also find a sample job to read a CSV inside.

## Git Sync

The entrypoint inside `gcp_gitsync_pyspark` allows people to just add the git credentials to 
this docker image instead of uploading your job code to a storage. 
If you don't want this behaviour, just remove this from the dockerfile.